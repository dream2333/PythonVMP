"""
PyVMé«˜çº§æ€§èƒ½åˆ†æå·¥å…·
æä¾›æ·±åº¦æ€§èƒ½åˆ†æå’Œä¼˜åŒ–å»ºè®®
"""

import sys
import os
import time
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', 'src'))

from compiler import tokenize, parse, generate_code
from vm import PyVirtualMachine, disassemble


class PerformanceAnalyzer:
    """æ€§èƒ½åˆ†æå™¨"""
    
    def __init__(self):
        self.results = {}
    
    def analyze_file(self, filepath: str, iterations: int = 1) -> dict:
        """åˆ†æå•ä¸ªæ–‡ä»¶çš„æ€§èƒ½"""
        print(f"=== åˆ†ææ–‡ä»¶: {filepath} ===")
        
        # è¯»å–æºæ–‡ä»¶
        with open(filepath, 'r', encoding='utf-8') as f:
            source = f.read()
        
        # ç¼–è¯‘
        print("ç¼–è¯‘é˜¶æ®µ...")
        compile_start = time.time()
        tokens = tokenize(source)
        ast = parse(tokens)
        constants, symbols, instructions = generate_code(ast)
        compile_time = time.time() - compile_start
        
        print(f"ç¼–è¯‘å®Œæˆ - è€—æ—¶: {compile_time:.4f}ç§’")
        print(f"ç”ŸæˆæŒ‡ä»¤æ•°: {len(instructions)}")
        print(f"å¸¸é‡æ•°: {len(constants)}")
        print(f"ç¬¦å·æ•°: {len(symbols)}")
        
        # å­—èŠ‚ç åˆ†æ
        print("\nå­—èŠ‚ç åˆ†æ:")
        bytecode_info = self.analyze_bytecode(instructions)
        
        # æ‰§è¡Œæ€§èƒ½æµ‹è¯•
        print(f"\næ‰§è¡Œæ€§èƒ½æµ‹è¯• (è¿­ä»£æ¬¡æ•°: {iterations})...")
        execution_results = []
        
        for i in range(iterations):
            vm = PyVirtualMachine(debug=False)
            vm.load_program(constants, symbols, instructions)
            
            start_time = time.time()
            vm.run()
            end_time = time.time()
            
            exec_time = end_time - start_time
            execution_results.append({
                'execution_time': exec_time,
                'instruction_count': vm.instruction_count,
                'instructions_per_second': vm.instruction_count / exec_time if exec_time > 0 else 0,
                'performance_report': vm.get_performance_report()
            })
        
        # ç»Ÿè®¡ç»“æœ
        avg_exec_time = sum(r['execution_time'] for r in execution_results) / iterations
        avg_inst_count = sum(r['instruction_count'] for r in execution_results) / iterations
        avg_ips = sum(r['instructions_per_second'] for r in execution_results) / iterations
        
        result = {
            'filepath': filepath,
            'compile_time': compile_time,
            'bytecode_info': bytecode_info,
            'execution_stats': {
                'iterations': iterations,
                'avg_execution_time': avg_exec_time,
                'avg_instruction_count': avg_inst_count,
                'avg_instructions_per_second': avg_ips,
                'min_execution_time': min(r['execution_time'] for r in execution_results),
                'max_execution_time': max(r['execution_time'] for r in execution_results),
            },
            'latest_performance_report': execution_results[-1]['performance_report'] if execution_results else None
        }
        
        self.results[filepath] = result
        return result
    
    def analyze_bytecode(self, instructions) -> dict:
        """åˆ†æå­—èŠ‚ç ç‰¹å¾"""
        opcode_counts = {}
        total_instructions = len(instructions)
        
        for instruction in instructions:
            opcode = instruction.opcode.name
            opcode_counts[opcode] = opcode_counts.get(opcode, 0) + 1
        
        # è®¡ç®—å¤æ‚åº¦æŒ‡æ ‡
        unique_opcodes = len(opcode_counts)
        most_common = max(opcode_counts.items(), key=lambda x: x[1])
        
        return {
            'total_instructions': total_instructions,
            'unique_opcodes': unique_opcodes,
            'opcode_distribution': opcode_counts,
            'most_common_opcode': most_common,
            'complexity_score': unique_opcodes / total_instructions if total_instructions > 0 else 0
        }
    
    def print_analysis_report(self, result: dict):
        """æ‰“å°åˆ†ææŠ¥å‘Š"""
        print(f"\n{'='*50}")
        print(f"æ€§èƒ½åˆ†ææŠ¥å‘Š: {result['filepath']}")
        print(f"{'='*50}")
        
        # ç¼–è¯‘ä¿¡æ¯
        print(f"\nç¼–è¯‘æ€§èƒ½:")
        print(f"  ç¼–è¯‘æ—¶é—´: {result['compile_time']:.4f}ç§’")
        
        # å­—èŠ‚ç ä¿¡æ¯
        bytecode = result['bytecode_info']
        print(f"\nå­—èŠ‚ç åˆ†æ:")
        print(f"  æ€»æŒ‡ä»¤æ•°: {bytecode['total_instructions']}")
        print(f"  å”¯ä¸€æ“ä½œç : {bytecode['unique_opcodes']}")
        print(f"  å¤æ‚åº¦åˆ†æ•°: {bytecode['complexity_score']:.3f}")
        print(f"  æœ€å¸¸è§æ“ä½œ: {bytecode['most_common_opcode'][0]} ({bytecode['most_common_opcode'][1]}æ¬¡)")
        
        # æ‰§è¡Œæ€§èƒ½
        exec_stats = result['execution_stats']
        print(f"\næ‰§è¡Œæ€§èƒ½:")
        print(f"  æµ‹è¯•è¿­ä»£: {exec_stats['iterations']}")
        print(f"  å¹³å‡æ‰§è¡Œæ—¶é—´: {exec_stats['avg_execution_time']:.4f}ç§’")
        print(f"  å¹³å‡æŒ‡ä»¤æ•°: {exec_stats['avg_instruction_count']:.0f}")
        print(f"  å¹³å‡æ‰§è¡Œé€Ÿåº¦: {exec_stats['avg_instructions_per_second']:.0f} æŒ‡ä»¤/ç§’")
        print(f"  æœ€å¿«æ‰§è¡Œ: {exec_stats['min_execution_time']:.4f}ç§’")
        print(f"  æœ€æ…¢æ‰§è¡Œ: {exec_stats['max_execution_time']:.4f}ç§’")
        
        # æ€§èƒ½å»ºè®®
        self.print_optimization_suggestions(result)
    
    def print_optimization_suggestions(self, result: dict):
        """æ‰“å°ä¼˜åŒ–å»ºè®®"""
        print(f"\nä¼˜åŒ–å»ºè®®:")
        
        exec_stats = result['execution_stats']
        bytecode = result['bytecode_info']
        
        # æ‰§è¡Œé€Ÿåº¦å»ºè®®
        avg_ips = exec_stats['avg_instructions_per_second']
        if avg_ips < 100000:
            print("  âš ï¸  æ‰§è¡Œé€Ÿåº¦è¾ƒæ…¢ï¼Œè€ƒè™‘å‡å°‘å¤æ‚è®¡ç®—")
        elif avg_ips > 1000000:
            print("  âœ… æ‰§è¡Œé€Ÿåº¦ä¼˜ç§€")
        else:
            print("  âœ“  æ‰§è¡Œé€Ÿåº¦è‰¯å¥½")
        
        # å­—èŠ‚ç å¤æ‚åº¦å»ºè®®
        complexity = bytecode['complexity_score']
        if complexity > 0.5:
            print("  âœ… ä»£ç ç»“æ„å¤æ‚ï¼ŒæŒ‡ä»¤å¤šæ ·æ€§é«˜")
        elif complexity < 0.1:
            print("  âš ï¸  ä»£ç ç»“æ„ç®€å•ï¼Œå¯èƒ½å­˜åœ¨ä¼˜åŒ–ç©ºé—´")
        else:
            print("  âœ“  ä»£ç å¤æ‚åº¦é€‚ä¸­")
        
        # æŒ‡ä»¤åˆ†å¸ƒå»ºè®®
        most_common = bytecode['most_common_opcode']
        if most_common[1] > bytecode['total_instructions'] * 0.5:
            print(f"  âš ï¸  æ“ä½œ {most_common[0]} ä½¿ç”¨é¢‘ç‡è¿‡é«˜ ({most_common[1]/bytecode['total_instructions']*100:.1f}%)")
        
        print("  ğŸ’¡ æç¤º: ä½¿ç”¨ --debug æ¨¡å¼æŸ¥çœ‹è¯¦ç»†æ‰§è¡Œè¿‡ç¨‹")


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python performance_analyzer.py <python_file> [iterations]")
        print("ç¤ºä¾‹: python performance_analyzer.py ../examples/fibonacci.py 5")
        sys.exit(1)
    
    filepath = sys.argv[1]
    iterations = int(sys.argv[2]) if len(sys.argv) > 2 else 3
    
    if not os.path.exists(filepath):
        print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ '{filepath}'")
        sys.exit(1)
    
    analyzer = PerformanceAnalyzer()
    
    try:
        result = analyzer.analyze_file(filepath, iterations)
        analyzer.print_analysis_report(result)
        
    except Exception as e:
        print(f"åˆ†æå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
